{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODOs\n",
    "&mdash; ~~Document pipeline tool~~\\\n",
    "&mdash; Document preprocessor\\\n",
    "&mdash; Agent that examines instructions, documents, and chat history to help determine the best course of action\\\n",
    "&mdash; Front-end chat interface with a document import that connects to the document ingestion pipe\\\n",
    "&mdash; Front-end chat interface that let's you dictate the system prompt\\\n",
    "&mdash; Haystack Retreivers and Readers\\\n",
    "&mdash; Prompts for the various LLMs invokes\\\n",
    "&mdash; Add a button to add your system prompt\\\n",
    "&mdash; Add a button to upload your docs (pdf's)\\"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ChatAI Prototype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompts \n",
    "\n",
    "from haystack.nodes import PromptTemplate\n",
    "\n",
    "\"\"\"\n",
    "'zero-shot-react'\n",
    "You are a helpful and knowledgeable agent. To achieve your goal of answering complex questions\n",
    "correctly, you have access to the following tools:\n",
    "\n",
    "{tool_names_with_descriptions}\n",
    "\n",
    "To answer questions, you'll need to go through multiple steps involving step-by-step thinking and\n",
    "selecting appropriate tools and their inputs; tools will respond with observations. When you are ready\n",
    "for a final answer, respond with the `Final Answer:`\n",
    "\n",
    "Use the following format:\n",
    "\n",
    "Question: the question to be answered\n",
    "Thought: Reason if you have the final answer. If yes, answer the question. If not, find out the missing information needed to answer it.\n",
    "Tool: pick one of {tool_names} \n",
    "Tool Input: the input for the tool\n",
    "Observation: the tool will respond with the result\n",
    "...\n",
    "\n",
    "Final Answer: the final answer to the question, make it short (1-5 words)\n",
    "Thought, Tool, Tool Input, and Observation steps can be repeated multiple times, but sometimes we can find an answer in the first pass\n",
    "---\n",
    "\n",
    "Question: {query}\n",
    "Thought: Let's think step-by-step, I first need to\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "\"\"\"\n",
    "'conversational-agent-without-tools'\n",
    "The following is a conversation between a human and an AI.\\n{memory}\\nHuman: {query}\\nAI:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# # # # # # # # # # # # # # # # # # # # # \n",
    "\n",
    "\"\"\"\n",
    "'conversational-summary'\n",
    "Condense the following chat transcript by shortening and summarizing the content \n",
    "without losing important information:\\n{chat_transcript}\\nCondensed Transcript:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "chatAgentPrompt = PromptTemplate(\n",
    "    prompt = \"\"\"\n",
    "    The following is a converation between a user and a virtual assistant. Given the context, provide the next best clear and concise response to the user's last question in 100 words or less. If you are unable to answer the question, you can say \"I'm sorry but I can't help with that\". {test} Context: {memory}; \n",
    "    Question: {query}; \n",
    "    Answer:\n",
    "    \"\"\"\n",
    ") \n",
    "\n",
    "chatSummaryPrompt = PromptTemplate(\n",
    "    prompt = \"\"\"\n",
    "    Summarize the following chat transcipt focusing only the most important information in the questions and responses. Be clear and concise and DO NOT lose the most relevant parts of the conversation: \\n\\n{chat_transcript}\\nCondensed Transcript:\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Document pre-processor\n",
    "\n",
    "# https://haystack.deepset.ai/tutorials/08_preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating BM25 representation...: 100%|██████████| 151/151 [00:00<00:00, 18859.51 docs/s]\n",
      "The prompt has been truncated from 938 tokens to 924 tokens so that the prompt length and answer length (100 tokens) fit within the max token limit (1024 tokens). Shorten the prompt to prevent it from being cut off.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Query: What does Rhodes Statue look like?'\n",
      "'Answers:'\n",
      "[   {   'answer': ' was the fate of the remains of the Colossus statue after '\n",
      "                  'it was destroyed, and who may have used the metal from the '\n",
      "                  'statue?\\n'\n",
      "                  '    Answer: The ultimate fate of the remains of the statue '\n",
      "                  'is uncertain, but it is unlikely that further maintenance '\n",
      "                  'or rebuilding was done on an ancient pagan statue after the '\n",
      "                  'city was Christianized in the 4th century. The metal may '\n",
      "                  'have been used for coins and tools during earlier conflicts '\n",
      "                  'such as the Sassanian wars, and by the'}]\n",
      "'Query: What does Taylor Swift look like?'\n",
      "'Answers:'\n",
      "[   {   'answer': ' Based solely on the given documents, it is not possible to '\n",
      "                  'answer this question as the documents do not contain any '\n",
      "                  \"information about Taylor Swift's appearance.\"}]\n"
     ]
    }
   ],
   "source": [
    "# Document Pipeline\n",
    "\n",
    "# Chat with Documemts\n",
    "# https://haystack.deepset.ai/tutorials/25_customizing_agent\n",
    "\n",
    "# Chat with Embeddings\n",
    "# https://haystack.deepset.ai/tutorials/23_answering_multihop_questions_with_agents\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from haystack.document_stores import InMemoryDocumentStore\n",
    "from haystack.nodes import PromptNode, PromptTemplate, AnswerParser, BM25Retriever\n",
    "from haystack.pipelines import Pipeline\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "remote_dataset = load_dataset(\"Tuana/presidents\", split=\"train\")\n",
    "\n",
    "document_store = InMemoryDocumentStore(use_bm25=True)\n",
    "document_store.write_documents(remote_dataset)\n",
    "\n",
    "from haystack.nodes import EmbeddingRetriever, FARMReader\n",
    "from haystack.pipelines import ExtractiveQAPipeline\n",
    "\n",
    "retriever = EmbeddingRetriever(\n",
    "    document_store=document_store,\n",
    "    embedding_model=\"sentence-transformers/multi-qa-mpnet-base-dot-v1\",\n",
    "    use_gpu=True\n",
    ")\n",
    "\n",
    "document_store.update_embeddings(retriever=retriever)\n",
    "reader = FARMReader(model_name_or_path=\"deepset/roberta-base-squad2\", use_gpu=True)\n",
    "presidents_qa = ExtractiveQAPipeline(reader=reader, retriever=retriever)\n",
    "\n",
    "from haystack.utils import print_answers\n",
    "\n",
    "# result = presidents_qa.run(\"Who was the 1st president of the USA?\")\n",
    "result = presidents_qa.run(\"What year was the 1st president of the USA born?\")\n",
    "\n",
    "print_answers(result, \"minimum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools for AI Agent\n",
    "\n",
    "from haystack.agents import Tool\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"seven_wonders_search\",\n",
    "    pipeline_or_node=generative_pipeline,\n",
    "    description=\"Useful for when you need to answer questions about the seven wonders of the world\",\n",
    "    output_variable=\"answers\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chat AI Agent\n",
    "\n",
    "import os\n",
    "from haystack.nodes import PromptNode\n",
    "from haystack.agents.conversational import ConversationalAgent\n",
    "from haystack.agents.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = PromptNode(\n",
    "    model_name_or_path = \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    api_key = os.getenv(\"HF_TOKEN\"),\n",
    "    max_length = 256,\n",
    "    model_kwargs = {\n",
    "        \"max_new_tokens\": 1000,\n",
    "        \"context_length\": 2500 \n",
    "    }\n",
    "    \n",
    ")\n",
    "\n",
    "chat_node = llm\n",
    "chat_node.stop_words = [\"\\nHuman\"]\n",
    "\n",
    "agentQuery = ConversationalAgent(\n",
    "    prompt_node = chat_node,\n",
    "    prompt_template = chatAgentPrompt,\n",
    "    max_steps = 2,\n",
    "    memory = ConversationSummaryMemory(\n",
    "        prompt_node = llm,\n",
    "        # prompt_template = chatSummaryPrompt,\n",
    "        summary_frequency = 4\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UI\n",
    "import gradio as gr\n",
    "\n",
    "def agentChat(message, history):\n",
    "    agentResponse = agentQuery.run(message)\n",
    "    agentResponse = agentResponse[\"answers\"][0].answer\n",
    "    \n",
    "    for i in range(len(agentResponse)):\n",
    "        time.sleep(0.03)\n",
    "        yield agentResponse[: i+1]\n",
    "\n",
    "# TODO Add a button to add your system prompt\n",
    "# TODO Add a button to upload your docs (pdf's)\n",
    "agentChat = gr.ChatInterface(\n",
    "    fn = agentChat,\n",
    ")\n",
    "\n",
    "agentChat.queue()\n",
    "agentChat.launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
